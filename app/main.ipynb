{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage of notebook\n",
    "\n",
    "This program simply tests that your setup is healthy\n",
    "If the output matches your machine feel free to delete and start programming!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_compute():\n",
    "    \"\"\"Check GPU and CPU availability and properties.\"\"\"\n",
    "    cpu_count = multiprocessing.cpu_count()\n",
    "    print(f\"CPU Cores Available: {cpu_count}\")\n",
    "\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    print(f\"GPU Available: {gpu_available}\")\n",
    "\n",
    "    if gpu_available:\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        print(f\"Number of GPUs: {gpu_count}\")\n",
    "        for i in range(gpu_count):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            gpu_memory = torch.cuda.get_device_properties(i).total_memory / (\n",
    "                1024**3\n",
    "            )  # GB\n",
    "            print(f\"GPU {i}: {gpu_name}, Memory: {gpu_memory:.2f} GB\")\n",
    "        current_device = torch.cuda.current_device()\n",
    "        print(f\"Current GPU Device: {current_device}\")\n",
    "    else:\n",
    "        print(\"Error: No GPU detected. Check NVIDIA drivers and runtime.\")\n",
    "\n",
    "\n",
    "def check_environment():\n",
    "    \"\"\"Check key environment variables and setup.\"\"\"\n",
    "    print(\"\\nEnvironment Checks:\")\n",
    "    for var in [\"PYTHONUNBUFFERED\", \"PYTHONDONTWRITEBYTECODE\", \"PYTHONFAULTHANDLER\"]:\n",
    "        value = os.getenv(var, \"Not set\")\n",
    "        print(f\"{var}: {value}\")\n",
    "\n",
    "    for path in [\"/app\", \"/data\", \"/logs\"]:\n",
    "        writable = os.access(path, os.W_OK)\n",
    "        print(f\"{path} writable: {writable}\")\n",
    "        if not writable:\n",
    "            print(f\"Error: {path} is not writable. Check volume mounts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running Docker Health Check...\\n\")\n",
    "\n",
    "check_compute()\n",
    "check_environment()\n",
    "if not torch.cuda.is_available() or not all(\n",
    "    os.access(p, os.W_OK) for p in [\"/app\", \"/data\", \"/logs\"]\n",
    "):\n",
    "    print(\"\\nHealth Check Failed!\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"\\nHealth Check Passed!\")\n",
    "sys.exit(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
